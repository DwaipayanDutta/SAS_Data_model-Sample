# Model Code for testing :
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import shap
import matplotlib.pyplot as plt
import pandas as pd

# Generate dataset
data_generator = DataGenerator(n_samples=10000)
dataset = data_generator.generate_dataset()

# Encode categorical variables to numerical values
categorical_cols = dataset.select_dtypes(include='object').columns
le = LabelEncoder()
for col in categorical_cols:
    dataset[col] = le.fit_transform(dataset[col])

# Fill missing values
dataset = dataset.fillna(0)

# Split the dataset into features and target
X = dataset.drop(['ACCOUNT_NO', 'LI_FLAG'], axis=1)
y = dataset['LI_FLAG']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define classifiers to evaluate
classifiers = {
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
    "Random Forest": RandomForestClassifier(),
    "Logistic Regression": LogisticRegression(max_iter=2000),  # Increased iterations
    "Support Vector Classifier": SVC(probability=True)
}

# Store results for comparison
results = {}

# Train and evaluate each classifier
for name, model in classifiers.items():
    if name in ["Logistic Regression"]:
        model.fit(X_train_scaled, y_train)  # Use scaled data for Logistic Regression
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)  # Use original data for other classifiers
        y_pred = model.predict(X_test)
    
    # Calculate accuracy
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy
    
    # Print confusion matrix and classification report
    print(f"\n{name} Results:")
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))
    print("\nClassification Report:")
    #print(classification_report(y_test, y_pred))
    print(classification_report(y_test, y_pred, zero_division=1))

# Determine the best classifier
best_classifier_name = max(results, key=results.get)
best_classifier_accuracy = results[best_classifier_name]

print(f"\nBest Classifier: {best_classifier_name} with Accuracy: {best_classifier_accuracy:.2f}")

# Explain the best model's predictions using SHAP values
best_model = classifiers[best_classifier_name]
explainer = shap.Explainer(best_model, X_train_scaled if best_classifier_name == "Logistic Regression" else X_train)
shap_values = explainer(X_test_scaled if best_classifier_name == "Logistic Regression" else X_test)

# Visualize the SHAP values
plt.figure(figsize=(10, 6))
shap.summary_plot(shap_values, X_test_scaled if best_classifier_name == "Logistic Regression" else X_test, plot_type="bar")
plt.show()
