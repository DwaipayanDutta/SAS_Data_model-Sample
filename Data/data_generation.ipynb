{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r'C:/Users/Vaishali/Documents/My Learning/Python/IBL PASA and Propensity/data/script/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = pd.read_excel('../data/mapping.xlsx', sheet_name='Sheet1')\n",
    "# mapping['STATE'] = mapping['STATE'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Updated_Data as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dt.DataGenerator(354645)\n",
    "df = data.generate_dataset().reset_index()\n",
    "df.rename(columns={'index':'ACCOUNT_NO'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACCOUNT_NO', 'ACCOUNT_TYPE', 'CUSTOMER_TAG', 'EDUCATION_LEVEL',\n",
       "       'GENDER', 'INTERNET_BANKING_USAGE', 'MARITAL_STATUS',\n",
       "       'NOMINEE_AVAILABLE_FLAG', 'RM_ALLOCATED_FLAG', 'OCCUPATION', 'STATE',\n",
       "       'FD_FLAG', 'GI_FLAG', 'HEALTH_FLAG', 'TARGET_LI', 'MASS_FLAG',\n",
       "       'MF_FLAG', 'NR_FLAG', 'ACCOUNT_NO', 'AGE', 'AQB_BALANCE', 'AUM',\n",
       "       'CIBIL_SCORE', 'CREDIT_CARD_LIMIT', 'CR_AMT_12MNTH', 'CR_CNT_12MNTH',\n",
       "       'DC_APPAREL_30DAYS_ACTV', 'DC_ECOM_30DAYS_AMT', 'DC_ECOM_30DAYS_CNT',\n",
       "       'DC_FOOD_30DAYS_ACTV', 'DC_FUEL_30DAYS_ACTV', 'DC_GROCRY_30DAYS_ACTV',\n",
       "       'DC_OTT_30DAYS_ACTV', 'DC_POS_30DAYS_AMT', 'DC_POS_30DAYS_CNT',\n",
       "       'DC_RECHARGE_30DAYS_ACTV', 'DC_TRAVEL_30DAYS_ACTV',\n",
       "       'DC_UTILITY_30DAYS_ACTV', 'DR_AMT_12MNTH', 'DR_CNT_12MNTH',\n",
       "       'DR_CR_RATIO', 'FD_COUNT', 'FD_CURRENTMONTHANR', 'INCOME_NET',\n",
       "       'MONTHLY_BALANCE', 'NRV', 'TOTAL_LIVE_SECURED_AMT',\n",
       "       'TOTAL_LIVE_UNSECURED_AMT', 'VINTAGE_DAYS', 'KYC_LAST_DONE_DATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marital Status\n",
    "df['MARITAL_STATUS'] = df['MARITAL_STATUS'].str.strip().str.upper()\n",
    "df['MARITAL_STATUS'] = np.where(df['MARITAL_STATUS'].isin(['WIDOW', 'DIVORCED', 'WIDOWER', 'LEGALLY SEPARATED']), 'WIDOWED/SEPARATED/DIVORCED', \n",
    "                                                          np.where(df['MARITAL_STATUS'].isin(['UNMARRIED', 'LIVE-IN RELATIONSHIP']), 'UNMARRIED/ SINGLE',\n",
    "                                                                                             np.where(df['MARITAL_STATUS'].isin(['UNMARRIED', 'LIVE-IN RELATIONSHIP']), 'UNMARRIED/ SINGLE', df['MARITAL_STATUS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occupation\n",
    "df['OCCUPATION'] = df['OCCUPATION'].str.strip().str.upper()\n",
    "df['OCCUPATION'] = np.where(df['OCCUPATION'].isin(['OTHERS','CURRENCY','TRANSACTION','INFORMATION TECHNOLOGY','SENP - OTHERS','CURRENT_EMPLOYMENT','FINANCE','SENP - MANUFACTURER','AGENCY','NON WORKING','TRADERS - SHARE / COMMODITY','SENP - SERVICE INDUSTRY','EVENT MANAGEMENT','BULLION / GEM / JEWEL / PRECIOUS METAL TRADER']), 'OTHERS', \n",
    "                            np.where(df['OCCUPATION'].isin(['BUSINESS','SMALL BUSINESSMAN','INDUSTRIALIST','DOCTOR','ART AND ANTIQUE DEALER','HARDWARE']), 'BUSINNESS OWNER', \n",
    "                                     np.where(df['OCCUPATION'].isin(['SALARIED','PVT EMPLOYEE','PROFESSIONAL','PUBLIC UTILITIES AND SERVICES','ENGINEER','ARCHITECT','MNC','DEFENCE FORCE']), 'SALARIED',\n",
    "                                              np.where(df['OCCUPATION'].isin(['SELF EMPLOYED','SELF EMPLOYEES PROFESSIONAL (SEP)','AGRICULTURE AND ALLIED ACTIVITIES','TRADER','DOCTOR/ DENTIST','GOVT SERVICE (SELF EMPLOYED)','LAWYER','REAL ESTATE BROKERS','ENGINEERING CONSULTANT','TRANSPORT OPERATOR','CHARTERED ACCOUNTANT','CONSULTANT','AGRICULTURE','Self employed','CA-CS','BROKERS','GOVT FREE LANCER','SHOPKEEPER','FARMER']), 'SELF EMPLOYED', df['OCCUPATION']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE\n",
       "Maharashtra                                 42525\n",
       "Gujarat                                     31945\n",
       "West Bengal                                 27924\n",
       "Uttar Pradesh                               25563\n",
       "Tamil Nadu                                  22887\n",
       "Haryana                                     22012\n",
       "Rajasthan                                   17927\n",
       "Punjab                                      17847\n",
       "Delhi                                       16733\n",
       "Madhya Pradesh                              15218\n",
       "Out of India                                12959\n",
       "Karnataka                                   11945\n",
       "Andhra Pradesh                              11654\n",
       "Telangana                                   11372\n",
       "Odisha                                      10700\n",
       "Kerala                                      10391\n",
       "Bihar                                       10291\n",
       "Assam                                        7397\n",
       "Chhattisgarh                                 6625\n",
       "Jharkhand                                    5589\n",
       "Uttarakhand                                  2585\n",
       "Himachal Pradesh                             2304\n",
       "Goa                                          1974\n",
       "Jammu and Kashmir                            1922\n",
       "Chandigarh                                   1895\n",
       "Manipur                                       865\n",
       "Nagaland                                      601\n",
       "Tripura                                       536\n",
       "Puducherry                                    526\n",
       "Dadra and Nagar Haveli and Daman and Diu      513\n",
       "Sikkim                                        446\n",
       "Arunachal Pradesh                             410\n",
       "Meghalaya                                     386\n",
       "Mizoram                                       167\n",
       "Andaman and Nicobar                            11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STATE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dic = {'STATE': {0: 'MAH',\n",
    "  1: 'DLI',\n",
    "  2: 'UTT',\n",
    "  3: 'GUJ',\n",
    "  4: 'HARY',\n",
    "  5: 'PUN',\n",
    "  6: 'WES',\n",
    "  7: 'RAJ',\n",
    "  8: 'TMU',\n",
    "  9: 'KRA',\n",
    "  10: 'ADH',\n",
    "  11: 'MDH',\n",
    "  12: 'BIH',\n",
    "  13: 'KER',\n",
    "  14: 'ORI',\n",
    "  15: 'JHA',\n",
    "  16: 'CHHA',\n",
    "  17: 'ASS',\n",
    "  18: 'TEA',\n",
    "  19: 'CA',\n",
    "  20: 'UTK',\n",
    "  21: 'HIM',\n",
    "  22: 'TLG',\n",
    "  23: 'JMR',\n",
    "  24: 'GOA',\n",
    "  25: 'CA)',\n",
    "  26: '.',\n",
    "  27: 'TRI',\n",
    "  28: 'SIK',\n",
    "  29: 'MNR',\n",
    "  30: 'PON',\n",
    "  31: 'NAG',\n",
    "  32: 'MEG',\n",
    "  33: 'DAD',\n",
    "  34: 'AUH',\n",
    "  35: 'MIZ',\n",
    "  36: 'DAM',\n",
    "  37: 'DUB',\n",
    "  38: 'ODISH',\n",
    "  39: 'US',\n",
    "  40: 'UTL',\n",
    "  41: 'AE',\n",
    "  42: 'JAR',\n",
    "  43: 'SG',\n",
    "  44: 'GB',\n",
    "  45: 'CHATT',\n",
    "  46: 'ABU',\n",
    "  47: 'ADR',\n",
    "  48: 'JP',\n",
    "  49: 'FRA',\n",
    "  50: 'CN',\n",
    "  51: 'LK',\n",
    "  52: 'SWE',\n",
    "  53: 'NG',\n",
    "  54: 'CDA',\n",
    "  55: 'ASA',\n",
    "  56: 'CAN',\n",
    "  57: 'UTTRA',\n",
    "  58: 'KR',\n",
    "  59: 'SA',\n",
    "  60: 'DHA',\n",
    "  61: 'AND',\n",
    "  62: 'MARY',\n",
    "  63: 'TEL',\n",
    "  64: 'NET',\n",
    "  65: 'NZ',\n",
    "  66: 'MUSC',\n",
    "  67: 'FOA',\n",
    "  68: 'LANTA',\n",
    "  69: 'KW',\n",
    "  70: 'SWI',\n",
    "  71: 'NWY',\n",
    "  72: 'DE',\n",
    "  73: 'BEL',\n",
    "  74: 'TEX',\n",
    "  75: 'LON',\n",
    "  76: 'CZ',\n",
    "  77: 'SHA',\n",
    "  78: 'KE',\n",
    "  79: 'GOI',\n",
    "  80: 'IT',\n",
    "  81: 'ONT',\n",
    "  82: 'BRN',\n",
    "  83: 'RSA',\n",
    "  84: 'KTU',\n",
    "  85: 'PUE',\n",
    "  86: 'KAM',\n",
    "  87: 'PENN',\n",
    "  88: 'DEL',\n",
    "  89: 'MY',\n",
    "  90: 'IND',\n",
    "  91: 'BNK',\n",
    "  92: 'DEC',\n",
    "  93: 'FR',\n",
    "  94: 'HAR',\n",
    "  95: 'TMS',\n",
    "  96: 'TOK',\n",
    "  97: 'NWK',\n",
    "  98: 'HK',\n",
    "  99: 'QAT',\n",
    "  100: 'BHN',\n",
    "  101: 'SAH',\n",
    "  102: 'KEN',\n",
    "  103: 'GEO',\n",
    "  104: 'NP',\n",
    "  105: 'NL',\n",
    "  106: 'HAMPS',\n",
    "  107: 'HAW',\n",
    "  108: 'PAT',\n",
    "  109: 'SING',\n",
    "  110: 'TLK',\n",
    "  111: 'MHM'},\n",
    " 'STATE_CAT': {0: 'MAHARASHTRA',\n",
    "  1: 'NRI OR OTHERS',\n",
    "  2: 'UTTAR PRADESH',\n",
    "  3: 'GUJARAT',\n",
    "  4: 'HARYANA',\n",
    "  5: 'PUNJAB',\n",
    "  6: 'WEST BENGAL',\n",
    "  7: 'RAJASTHAN',\n",
    "  8: 'TAMIL NADU',\n",
    "  9: 'KARNATAKA',\n",
    "  10: 'ANDHRA PRADESH',\n",
    "  11: 'MADHYA PRADESH',\n",
    "  12: 'BIHAR',\n",
    "  13: 'KERALA',\n",
    "  14: 'ORISSA',\n",
    "  15: 'JHARKHAND',\n",
    "  16: 'CHHATTISGARH',\n",
    "  17: 'ASSAM',\n",
    "  18: 'NRI OR OTHERS',\n",
    "  19: 'NRI OR OTHERS',\n",
    "  20: 'UTTARAKHAND',\n",
    "  21: 'HIMACHAL PRADESH',\n",
    "  22: 'NRI OR OTHERS',\n",
    "  23: 'JAMMU & KASHMIR',\n",
    "  24: 'GOA',\n",
    "  25: 'NRI OR OTHERS',\n",
    "  26: 'NRI OR OTHERS',\n",
    "  27: 'TIRIPURA',\n",
    "  28: 'SIKKIM',\n",
    "  29: 'MANIPUR',\n",
    "  30: 'PONDICHERRY',\n",
    "  31: 'NAGALAND',\n",
    "  32: 'MEGALAYA',\n",
    "  33: 'DADRA & NAGAR HAVELI',\n",
    "  34: 'NRI OR OTHERS',\n",
    "  35: 'MIZORAM',\n",
    "  36: 'DAMAN AND DIU',\n",
    "  37: 'NRI OR OTHERS',\n",
    "  38: 'ORISSA',\n",
    "  39: 'NRI OR OTHERS',\n",
    "  40: 'NRI OR OTHERS',\n",
    "  41: 'NRI OR OTHERS',\n",
    "  42: 'NRI OR OTHERS',\n",
    "  43: 'NRI OR OTHERS',\n",
    "  44: 'NRI OR OTHERS',\n",
    "  45: 'CHHATTISGARH',\n",
    "  46: 'NRI OR OTHERS',\n",
    "  47: 'NRI OR OTHERS',\n",
    "  48: 'NRI OR OTHERS',\n",
    "  49: 'NRI OR OTHERS',\n",
    "  50: 'NRI OR OTHERS',\n",
    "  51: 'NRI OR OTHERS',\n",
    "  52: 'NRI OR OTHERS',\n",
    "  53: 'NRI OR OTHERS',\n",
    "  54: 'NRI OR OTHERS',\n",
    "  55: 'NRI OR OTHERS',\n",
    "  56: 'NRI OR OTHERS',\n",
    "  57: 'UTTARANCHAL',\n",
    "  58: 'NRI OR OTHERS',\n",
    "  59: 'NRI OR OTHERS',\n",
    "  60: 'NRI OR OTHERS',\n",
    "  61: 'ANDAMAN AND NICOBAR',\n",
    "  62: 'NRI OR OTHERS',\n",
    "  63: 'TELANGANA',\n",
    "  64: 'NRI OR OTHERS',\n",
    "  65: 'NRI OR OTHERS',\n",
    "  66: 'NRI OR OTHERS',\n",
    "  67: 'NRI OR OTHERS',\n",
    "  68: 'NRI OR OTHERS',\n",
    "  69: 'NRI OR OTHERS',\n",
    "  70: 'NRI OR OTHERS',\n",
    "  71: 'NRI OR OTHERS',\n",
    "  72: 'NRI OR OTHERS',\n",
    "  73: 'NRI OR OTHERS',\n",
    "  74: 'NRI OR OTHERS',\n",
    "  75: 'NRI OR OTHERS',\n",
    "  76: 'NRI OR OTHERS',\n",
    "  77: 'NRI OR OTHERS',\n",
    "  78: 'NRI OR OTHERS',\n",
    "  79: 'NRI OR OTHERS',\n",
    "  80: 'NRI OR OTHERS',\n",
    "  81: 'NRI OR OTHERS',\n",
    "  82: 'NRI OR OTHERS',\n",
    "  83: 'NRI OR OTHERS',\n",
    "  84: 'NRI OR OTHERS',\n",
    "  85: 'NRI OR OTHERS',\n",
    "  86: 'NRI OR OTHERS',\n",
    "  87: 'NRI OR OTHERS',\n",
    "  88: 'DELHI',\n",
    "  89: 'NRI OR OTHERS',\n",
    "  90: 'NRI OR OTHERS',\n",
    "  91: 'NRI OR OTHERS',\n",
    "  92: 'NRI OR OTHERS',\n",
    "  93: 'NRI OR OTHERS',\n",
    "  94: 'NRI OR OTHERS',\n",
    "  95: 'NRI OR OTHERS',\n",
    "  96: 'NRI OR OTHERS',\n",
    "  97: 'NRI OR OTHERS',\n",
    "  98: 'NRI OR OTHERS',\n",
    "  99: 'NRI OR OTHERS',\n",
    "  100: 'NRI OR OTHERS',\n",
    "  101: 'NRI OR OTHERS',\n",
    "  102: 'NRI OR OTHERS',\n",
    "  103: 'NRI OR OTHERS',\n",
    "  104: 'NRI OR OTHERS',\n",
    "  105: 'NRI OR OTHERS',\n",
    "  106: 'NRI OR OTHERS',\n",
    "  107: 'NRI OR OTHERS',\n",
    "  108: 'NRI OR OTHERS',\n",
    "  109: 'NRI OR OTHERS',\n",
    "  110: 'NRI OR OTHERS',\n",
    "  111: 'NRI OR OTHERS'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_map = pd.DataFrame(state_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(df, state_map, on = 'STATE', how = 'left') # This line needs to be uncommented before sharing it with IBL\n",
    "df['STATE_CAT'] = df['STATE'].str.strip().str.upper() # this line needs to be commented before sharing with IBL\n",
    "\n",
    "north = ['DELHI','HARYANA','UTTAR PRADESH','CHANDIGARH','RAJASTHAN','PUNJAB','UTTARANCHAL','JAMMU & KASHMIR','HIMACHAL PRADESH','UTTARAKHAND','MADHYA PRADESH']\n",
    "east = ['WEST BENGAL','CHHATTISGARH','JHARKHAND','ORISSA','ASSAM','BIHAR','TRIPURA','SIKKIM','MEGHALAYA','MANIPUR','ARUNACHAL PRADESH','MIZORAM','NAGALAND']\n",
    "west = ['RAJASTHAN','MAHARASHTRA','GOA','GUJARAT','MADHYA PRADESH','DAMAN AND DIU','DADRA & NAGAR HAVELI']\n",
    "south = ['ANDHRA PRADESH','KARNATAKA','TAMIL NADU','TELANGANA','KERALA','PONDICHERRY']\n",
    "\n",
    "df['ZONE'] = np.where(df['STATE_CAT'].isin(north), 'NORTH', \n",
    "                      np.where(df['STATE_CAT'].isin(east), 'EAST',\n",
    "                               np.where(df['STATE_CAT'].isin(west), 'WEST',\n",
    "                                        np.where(df['STATE_CAT'].isin(south), 'SOUTH', 'NRI/ OUT OF INDIA'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KYC_LAST_DONE_DATE'] = pd.to_datetime(df['KYC_LAST_DONE_DATE'])\n",
    "df = df[~df['KYC_LAST_DONE_DATE'].isna()].reset_index(drop = True)\n",
    "df['KYC_RECENCY_YEARS'] = (datetime.now() - df['KYC_LAST_DONE_DATE'])/np.timedelta64(1, 'D')/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create buckets\n",
    "def assign_bucket(var, ranges, label):\n",
    "    for i, range in enumerate(ranges):\n",
    "        if var > range:\n",
    "            return label[i]\n",
    "    return label[-1] if var > range[-1] else 'Not Available'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyc_ranges = [0.5, 1, 3, 5]\n",
    "kyc_labels = ['Less than 6 Months', '6 Months to 1 Year', '1 to 3 Years', '3 to 5 Years', 'More than 5 Years']\n",
    "\n",
    "df['KYC_RECENCY_BUCKET'] = df['KYC_RECENCY_YEARS'].apply(assign_bucket, args = (kyc_ranges,kyc_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ACCOUNT_TYPE',\n",
    "'CUSTOMER_TAG', # Has lot of values - need input from the bank\n",
    "'EDUCATION_LEVEL',\n",
    "'GENDER',\n",
    "'INTERNET_BANKING_USAGE',\n",
    "'MARITAL_STATUS',\n",
    "'NOMINEE_AVAILABLE_FLAG',\n",
    "'RM_ALLOCATED_FLAG',\n",
    "'OCCUPATION',\n",
    "# 'STATE',\n",
    "'KYC_RECENCY_BUCKET', # Derived\n",
    "'FD_FLAG', \n",
    "'GI_FLAG', \n",
    "'HEALTH_FLAG', \n",
    "'MASS_FLAG', \n",
    "'MF_FLAG', \n",
    "'NR_FLAG',\n",
    "'ZONE' # Derived\n",
    "]\n",
    "\n",
    "num_cols = ['AGE', 'AQB_BALANCE', 'AUM', 'CIBIL_SCORE', 'CREDIT_CARD_LIMIT', 'CR_AMT_12MNTH', 'CR_CNT_12MNTH',\n",
    "            'DC_APPAREL_30DAYS_ACTV', 'DC_ECOM_30DAYS_AMT', 'DC_ECOM_30DAYS_CNT', 'DC_FOOD_30DAYS_ACTV',\n",
    "            'DC_FUEL_30DAYS_ACTV', 'DC_GROCRY_30DAYS_ACTV', 'DC_OTT_30DAYS_ACTV', 'DC_POS_30DAYS_AMT',\n",
    "            'DC_POS_30DAYS_CNT', 'DC_RECHARGE_30DAYS_ACTV', 'DC_TRAVEL_30DAYS_ACTV', 'DC_UTILITY_30DAYS_ACTV',\n",
    "            'DR_AMT_12MNTH', 'DR_CNT_12MNTH', 'DR_CR_RATIO', 'FD_COUNT', 'FD_CURRENTMONTHANR',  # 'INCOME_NET', removing due to less fill rate\n",
    "            'MONTHLY_BALANCE', 'NRV', 'TOTAL_LIVE_SECURED_AMT', 'TOTAL_LIVE_UNSECURED_AMT',\n",
    "            'VINTAGE_DAYS']\n",
    "\n",
    "target = ['TARGET_LI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value treatment for categorical variables\n",
    "for cat in cat_cols:\n",
    "    df[cat] = np.where(df[cat].isna(), 'Not Available', df[cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test_valid = train_test_split(df, test_size=0.4, random_state=42, stratify=df['TARGET_LI'])\n",
    "test, valid = train_test_split(test_valid, test_size=0.5, random_state=42, stratify=test_valid['TARGET_LI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET_LI\n",
       "N    0.850677\n",
       "Y    0.149323\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['TARGET_LI'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET_LI\n",
       "N    0.850668\n",
       "Y    0.149332\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['TARGET_LI'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET_LI\n",
       "N    0.850682\n",
       "Y    0.149318\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid['TARGET_LI'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value treatment for continuous variables\n",
    "# We are assuming that all the continious variables are skewed and median will be the better representative of the central tendency\n",
    "# Hence we will replace any missing value with respective median value\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputer_fit = imputer.fit(train[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[num_cols] = imputer_fit.fit_transform(train[num_cols])\n",
    "test[num_cols] = imputer_fit.fit_transform(test[num_cols])\n",
    "valid[num_cols] = imputer_fit.fit_transform(valid[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numerical parameters using standard scaler\n",
    "scaler = StandardScaler()\n",
    "scaler_fit = scaler.fit(train[num_cols])\n",
    "\n",
    "train[num_cols] = scaler_fit.fit_transform(train[num_cols])\n",
    "test[num_cols] = scaler_fit.fit_transform(test[num_cols])\n",
    "valid[num_cols] = scaler_fit.fit_transform(valid[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding categorical variables\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "for col in cat_cols:\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.fit_transform(test[col])\n",
    "    valid[col] = le.fit_transform(valid[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, classifiers):\n",
    "        self.classifiers = classifiers\n",
    "        self.results = {}\n",
    "\n",
    "    def train_and_evaluate(self, X_train, y_train, X_test, y_test):\n",
    "        for name, model in self.classifiers.items():\n",
    "            print(f\"Training {name}...\")\n",
    "            if name == \"Logistic Regression\":\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            self.results[name] = accuracy\n",
    "            \n",
    "            # Print confusion matrix and classification report\n",
    "            print(f\"\\n{name} Results:\")\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = ModelEvaluator(classifiers=classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "\n",
      "Random Forest Results:\n",
      "Confusion Matrix:\n",
      "[[60337     0]\n",
      " [10592     0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.85      1.00      0.92     60337\n",
      "           Y       1.00      0.00      0.00     10592\n",
      "\n",
      "    accuracy                           0.85     70929\n",
      "   macro avg       0.93      0.50      0.46     70929\n",
      "weighted avg       0.87      0.85      0.78     70929\n",
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Results:\n",
      "Confusion Matrix:\n",
      "[[60337     0]\n",
      " [10592     0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.85      1.00      0.92     60337\n",
      "           Y       1.00      0.00      0.00     10592\n",
      "\n",
      "    accuracy                           0.85     70929\n",
      "   macro avg       0.93      0.50      0.46     70929\n",
      "weighted avg       0.87      0.85      0.78     70929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_obj.train_and_evaluate(X_train=train[cat_cols + num_cols], y_train=train['TARGET_LI'], X_test=test[cat_cols + num_cols], y_test=test['TARGET_LI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
